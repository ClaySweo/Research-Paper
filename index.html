<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css" href="style.css">
    <title>Graphics Cards</title>
</head>
<body>
    <h1 class="green">The History of Graphics Cards and CPUs</h1>
    <hr>
    <a href="https://wccftech.com/nvidia-launches-geforce-gt-710/"><img src="https://th.bing.com/th/id/R.2bd2f623360e5b5c8bf2c03a3fa43bf3?rik=xJV%2fY6aHALnvRA&riu=http%3a%2f%2fcdn.wccftech.com%2fwp-content%2fuploads%2f2016%2f01%2fGigabyte-GeForce-GT-710_1-GB.png&ehk=9L%2fUzJUF00RwZ1SbZyg0c2YUw7qZETT9gYteJ%2foD7XA%3d&risl=&pid=ImgRaw&r=0"></a>
    <a href="http://ijirst.org/PCI-Express-Graphics-Cards/255103-OC-MSI-GeForce/"><img src="https://storage-asset.msi.com/global/picture/image/feature/vga/NVIDIA/RTX2060/Ventus/2060-ventus-xs-intro.png"></a>
    <a href="http://superuser.com/questions/215622/evga-nvidia-gt-240-intermittently-stops-working"><img src="https://th.bing.com/th/id/R.25a451fc904f38ae6be12b4c0c874144?rik=boglOueLJy8lVg&riu=http%3a%2f%2fi.stack.imgur.com%2feemmI.png&ehk=YR1bcrQzzqDr%2fJIUMmha24wvOFyfb5lIit38Di5tAv4%3d&risl=&pid=ImgRaw&r=0"></a>
    <a href="http://wccftech.com/nvidia-launches-geforce-gt-710/"><img src="https://th.bing.com/th/id/R.6bb7feceaf5459764c05219efabaf967?rik=FptflVEKsFKB3w&riu=http%3a%2f%2fcdn.wccftech.com%2fwp-content%2fuploads%2f2016%2f01%2fMSI-GeForce-GT-710_3.png&ehk=Zp3fLlavfG0okz1NXbibcvD82AtsFHiL1zNZEQQjbko%3d&risl=&pid=ImgRaw&r=0"></a>
    <a href="http://wccftech.com/msi-geforce-gtx-1060/"><img src="https://th.bing.com/th/id/R.d4202b2676bc53be91c9ded2ac84c865?rik=tYd6zomXRIcjZw&riu=http%3a%2f%2fcdn.wccftech.com%2fwp-content%2fuploads%2f2016%2f07%2f5-2-635x508.png&ehk=TCS9f0YbnrVOCP1j%2bBLfEHeBrZUuSHWDjubCRVNPX9Q%3d&risl=&pid=ImgRaw&r=0"></a>
    <hr>
    <br>
    <hr>
    <h2 class="green">GeForce 256</h2>
    <hr>
    <p>NVIDIA started their journey in the industry of graphics cards just before the turn of the century. On October 11, 1999. Nvidia released the first version of their <i>GeForce 256</i>, which significantly outperformed graphics chips that had been made in the past. This was marketed to consumers as the first full GPU, as it contained all of the engines and components to process over 10 million polygons a second. Modern graphics cards can perform at much higher levels than this, but none can replicate the impact this GPU had on the computing industry. Video games and computers graphics are limited by the lack of processing power in their time, so when something this monumental was released, great improvement is bound to be made.</p>
    <p>The burden of tasks like video gaming on the system was so great that they could not be done efficiently without a dedicated piece of hardware. This is where the <i>GeForce 256</i> fit into its place, as it sped up these processes by 50% or more. Despite this performance boost, the <i>GeForce 256</i> underperformed compared to its competitors when using a higher end or higher performance CPU. This was one of the main criticisms for "the first ever graphics processing unit" as its high price did not justify the subpar performance on high quality CPUs. Very little support existed for the <i>GeForce 256</i> when it came out, so much of the performance was unusable in application; the GPU could not even be installed in most motherboards on release day.</p>
    <hr>
    <a href="https://en.wikipedia.org/wiki/GeForce_256"> <img class="center-image" src="https://th.bing.com/th/id/R.ffce67fffd44f2f0411d1771b8c74a83?rik=ZIF1oieLyw4nyg&pid=ImgRaw&r=0&sres=1&sresct=1"></a>
    <p id="source">Source: Creative Commons</p>
    <hr>
    <br>
    <hr>
    <h2 class="green2">Intel 4004</h2>
    <hr>
    <p>Although a GPU is vital to any demanding process on a computer today, the first GPU was significantly predated by the first CPU. The CPU does most of the non-graphical calculations on a computer, causing it to be used at almost all times; this is why the first CPU was released much before the first GPU. This first CPU, the <i>Intel 4004</i>, was put onto the market on November 15, 1971, which was around 50 years ago. Microprocessors had existed before the <i>Intel 4004</i>, but none were put into the commercial market for various reasons, such as price or size. These tiny processors utilized a silicon gate architecture to perform calculations at blazing fast speeds.
         Much of the development for the <i>Intel 4004</i> was credited to Federico Faggin, who created the project behind the engineering of the chip.
         Every other processor before the <i>Intel 4004</i> was not a real CPU, since all of them had different parts and mechanisms happening outside of the center chip. On its release, the CPU was used only in a specific type of calculator and a pinball game. Despite this, the <i>Intel 4004</i> was considered to be used in the Pioneer 10 spacecraft, which was used to leave the solar system. The engineers for this craft did not deny the CPU for any problems with its hardware, but because it was too new at the time to be completely trusted. As is common with computer parts that are as revolutionary as this one, the pricing was too much for most consumers to justify the use cases.
         The <i>Intel 4004</i> will still go down as important history of the computer as it led to many important advancements for the future.</p>
    <hr>
    <a href="https://mlpp.pressbooks.pub/historyofhightech/chapter/semiconductors-and-ics/"> <img class="center-image" src="https://mlpp.pressbooks.pub/app/uploads/sites/622/2019/09/Intel_C4004.jpg"></a>
    <p id="source">Source: Creative Commons</p>
    <hr>
    <br>
    <hr>
    <h2 class="green3">MOS Technology 6502</h2>
    <hr>
    <p>Despite the prior achievements with the first CPU and GPU, there were few applications of these great tools. This was changed by the <i>MOS Technology 6502</i>, which was one of the most impactful CPU's of its time. The chip was created by a small group who called themselves Mos Technology in 1975. It was used in many computers and video game consoles, like the Atari 2600, Apple II, Nintendo Entertainment System, Commodore 64, and the Atari Lynx. 
        These machines revolutionized their respective industry, as they ushered in the golden age of gaming. One of the greatest features of the <i>MOS Technology 6502</i> was its price, as it was cheap enough to place into consoles which could be marketed to the middle class. 
       The great power contrasted the affordable price by so much that all other competitors had to lower their prices, as they could not compete. Almost all people from the team of creators of the <i>MOS  
       Technology 6502</i> originated at Motorola, which soon became another of their competitors. In spite of this, everything used the MOS processor as it was just this far ahead.  
       Most people did not have a computer at home until the revolution this CPU started; this computer revolution made computers cheap and small enough to allow every family to have one. The success of the <i>MOS Technology 6502</i> was so great that the MOS Technology group received a lawsuit from Motorola, their former employer.  
       This lawsuit ended with an agreement to share patents, allowed both companies to further technology. </p>
    <hr>
    <a href="https://www.timetoast.com/timelines/evolucion-del-procesador-d8acd1ac-fb25-4335-8c65-b70a91c4d620"> <img class="center-image" src="https://s3.amazonaws.com/s3.timetoast.com/public/uploads/photos/10833157/esta.jpg"></a>   
    <p id="source">Source: Jesus David Acevedo. MOS Technology 6502. timetoast.com (https://www.timetoast.com/timelines/evolucion-del-procesador-d8acd1ac-fb25-4335-8c65-b70a91c4d620)</p>
    <hr>
    <br>
    <hr>
    <h2 class="green4">GTX 1080</h2>
    <hr>
    <p>All of these computer parts were massively influential in the 90's, yet none of them hold up in today's world. That is where the <i>GTX 1080</i> differs, which came out very recently in May 27, 2016. 
        This GPU was the pinnacle of technology on its release date, being highly priced and sought after for its performance. It was marketed as a higher end GPU, which fitted the price tag that most could not afford. The <i>GTX 1080</i> was released with the rest of the NVIDIA 10 series GPU's, and was only exceeded in performance by three of them. 
        Before the 10 series, the computer market had stagnated in higher quality parts; NVIDIA changed this greatly with some of the best graphics cards to date. The <i>GTX 1080</i> and the GTX 1070 were the first to be released under the new Pascal architecture, which outperformed the older Maxwell architecture. This new architecture made way for SLI Bridge Technology, which allowed the user to connect multiple GPU's together for increased performance on some tasks. Another new feature was the triple buffering ability, which stopped screen tearing without compromising speeds at the cost of extra VRAM usage. 
        All of these features were introduced with the Founders Edition, which is the first version released solely by NVIDIA. After the release of every GPU, partnered manufacturers create their own versions of the product, which usually improve cooling or other small performance issues. These versions are often what makes a graphics card, yet the Founders Edition of the <i>GTX 1080</i> changed the market without them.</p>
    <hr>
    <a href="https://www.nvidia.com/en-us/geforce/news/geforce-gtx-1080/"> <img class="center-image" src="https://www.nvidia.com/content/dam/en-zz/Solutions/geforce/news/geforce-gtx-1080/nvidia-geforce-gtx-1080-photo-640px.jpg"></a>   
    <p id="source">Source: Andrew Burnes. GTX 1080. nvidia.com (https://www.nvidia.com/en-us/geforce/news/geforce-gtx-1080/)</p>
</body>
</html>